{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pxxxxxxx123446/libsvm/blob/master/HW8/ML2022Spring_HW8_strong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiVfKn-6tXz8"
      },
      "source": [
        "# **Homework 8 - Anomaly Detection**\n",
        "\n",
        "If there are any questions, please contact mlta-2022spring-ta@googlegroups.com\n",
        "\n",
        "Slide:    [Link]()　Kaggle: [Link](https://www.kaggle.com/c/ml2022spring-hw8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDk9r2YOcDc9"
      },
      "source": [
        "# Set up the environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi12tJMYWi0Q"
      },
      "source": [
        "## Package installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LexxyPWWjJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437b60ec-8a40-4090-c86e-1a191c819bfa"
      },
      "source": [
        "# Training progress bar\n",
        "!pip install qqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qqdm\n",
            "  Downloading qqdm-0.0.7.tar.gz (5.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from qqdm)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting jupyter (from qqdm)\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm) (7.16.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter->qqdm)\n",
            "  Downloading jupyterlab-4.3.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->qqdm) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->qqdm) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->qqdm) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->qqdm) (2.18.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->qqdm)\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->qqdm) (0.27.2)\n",
            "Collecting ipykernel (from jupyter->qqdm)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->qqdm) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->qqdm) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->qqdm)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter->qqdm)\n",
            "  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->qqdm)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->qqdm) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->qqdm) (24.2)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->qqdm) (75.1.0)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->qqdm) (2.1.0)\n",
            "Collecting comm>=0.1.1 (from ipykernel->jupyter->qqdm)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (1.8.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm) (24.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm) (1.4.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from async-lru>=1.0.0->jupyterlab->jupyter->qqdm) (4.12.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert->jupyter->qqdm) (0.5.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->qqdm) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->qqdm) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->qqdm) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->qqdm) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->qqdm) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->qqdm) (0.14.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter->qqdm)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter->qqdm) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab->jupyter->qqdm) (4.3.6)\n",
            "Collecting jupyter-client (from jupyter-console->jupyter->qqdm)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->qqdm) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from jupyter-client->jupyter-console->jupyter->qqdm) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm) (2.16.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm)\n",
            "  Downloading json5-0.9.28-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm) (2.32.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert->jupyter->qqdm) (2.20.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->qqdm) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter->qqdm) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->qqdm) (2.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->qqdm) (1.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->qqdm) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm) (0.21.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel->jupyter->qqdm) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->qqdm) (2.2.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->qqdm) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->qqdm) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->qqdm)\n",
            "  Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl.metadata (1.9 kB)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyterlab-4.3.1-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.9.28-py3-none-any.whl (30 kB)\n",
            "Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)\n",
            "Building wheels for collected packages: qqdm\n",
            "  Building wheel for qqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qqdm: filename=qqdm-0.0.7-py3-none-any.whl size=6467 sha256=f455f0e613e51eaf11c75648fa8d1a37dcd285e279c6854b0bf37ca3874e8f48\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1a/56/5dccdea123a172661eb65c8c29fde4567dbda2b72b5fc5893a\n",
            "Successfully built qqdm\n",
            "Installing collected packages: addict, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, json5, jedi, fqdn, comm, async-lru, jupyter-server-terminals, jupyter-client, arrow, isoduration, ipykernel, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter, qqdm\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed addict-2.4.0 arrow-1.3.0 async-lru-2.0.4 comm-0.2.2 fqdn-1.5.1 ipykernel-6.29.5 isoduration-20.11.0 jedi-0.19.2 json5-0.9.28 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.3.1 jupyterlab-server-2.27.3 overrides-7.7.0 python-json-logger-2.0.7 qqdm-0.0.7 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241003 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCgNXSsEWuY7"
      },
      "source": [
        "## Downloading data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y50WV8TDjDhk",
        "outputId": "2f042687-141c-4b31-ab9e-cf74857a89ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "token = {\"username\":\"xiaoxiapanx\",\"key\":\"b1ad1e8363da5ba1933fd8d4d236430e\"}\n",
        "with open('/content/kaggle.json', 'w') as file:\n",
        "  json.dump(token, file)"
      ],
      "metadata": {
        "id": "G4BT83K6mDCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./kaggle"
      ],
      "metadata": {
        "id": "UlKSQyV1mP_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/kaggle.json ./kaggle/"
      ],
      "metadata": {
        "id": "xlv0Axh3mvTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p root/.config/kaggle\n",
        "!mv /content/kaggle.json ~/.config/kaggle/\n"
      ],
      "metadata": {
        "id": "mBbUFvawmDol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ./kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "qfgZXuyDm2-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQGKyD1xm6DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c ml2022spring-hw8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvvLobJyksuo",
        "outputId": "2a826b24-c8b9-4673-c90c-2737948933aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.config/kaggle/kaggle.json'\n",
            "Downloading ml2022spring-hw8.zip to /content\n",
            "100% 1.14G/1.14G [01:02<00:00, 20.4MB/s]\n",
            "100% 1.14G/1.14G [01:02<00:00, 19.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle https://github.com/MachineLearningHW/HW8_Dataset/releases/download/v1.0.0/data.zip"
      ],
      "metadata": {
        "id": "SCLJtgF2BLSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7a7e1e-4d4a-4bf8-ad25-3891442a0d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-17 09:51:12--  https://github.com/MachineLearningHW/HW8_Dataset/releases/download/v1.0.0/data.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-11-17 09:51:12 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vEkfWEMtnWig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K5kmlkuWzhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb8562b-f059-4ec9-9d83-3685e4ebb335"
      },
      "source": [
        "!unzip /content/ml2022spring-hw8.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/ml2022spring-hw8.zip\n",
            "  inflating: data/testingset.npy     \n",
            "  inflating: data/trainingset.npy    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNe7QU7n7cqh"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk3qFK_a7k8P"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision.models as models\n",
        "from torch.optim import Adam, AdamW\n",
        "from qqdm import qqdm, format_str\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X6fkGPnYyaF"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Wd4yiUYzAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b20ec8-0a76-4bfb-8381-7fe22b683d43"
      },
      "source": [
        "\n",
        "train = np.load('data/trainingset.npy', allow_pickle=True)\n",
        "test = np.load('data/testingset.npy', allow_pickle=True)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 64, 64, 3)\n",
            "(19636, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_flpmj6OYIa6"
      },
      "source": [
        "## Random seed\n",
        "Set the random seed to a certain value for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb-dgXQYYI2Q"
      },
      "source": [
        "def same_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(48763)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR9zC0_Df-CR"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EbfwRREhA7c"
      },
      "source": [
        "# Models & loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class multi_encoder_autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        print(\"hhhhhhhhhhhhhhhh\")\n",
        "        super(multi_encoder_autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder 1\n",
        "        self.encoder1 = nn.Sequential(\n",
        "            nn.Linear(64 * 64 * 3, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128)\n",
        "        )\n",
        "\n",
        "        # Encoder 2\n",
        "        self.encoder2 = nn.Sequential(\n",
        "            nn.Linear(64 * 64 * 3, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128)\n",
        "        )\n",
        "\n",
        "        # Bottleneck layer to combine encodings\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Linear(128 * 2, 64),  # Combine outputs from two encoders\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(10, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 64 * 64 * 3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"\n",
        "        x1: Input for encoder 1\n",
        "        x2: Input for encoder 2\n",
        "        \"\"\"\n",
        "        h1 = self.encoder1(x)\n",
        "        h2 = self.encoder2(x)\n",
        "        return h1, h2\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(f\"Forward received x: {x.shape}\")\n",
        "        # Encode inputs\n",
        "        h1, h2 = self.encode(x)\n",
        "\n",
        "        # Concatenate encoded features\n",
        "        combined = torch.cat((h1, h2), dim=1)\n",
        "\n",
        "        # Pass through bottleneck\n",
        "        z = self.bottleneck(combined)\n",
        "\n",
        "        # Decode from bottleneck\n",
        "        x_reconstructed = self.decoder(z)\n",
        "        return x_reconstructed\n"
      ],
      "metadata": {
        "id": "Dk-amHty4TdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi8ds1fugCkR"
      },
      "source": [
        "class fcn_autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(fcn_autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(64 * 64 * 3, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(10, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 64 * 64 * 3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class conv_autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(conv_autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 12, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(12, 24, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "\t\t\t      nn.Conv2d(24, 48, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "\t\t\t      nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "\t\t\t      nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 12, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(12, 24, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.enc_out_1 = nn.Sequential(\n",
        "            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.enc_out_2 = nn.Sequential(\n",
        "            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "\t\t\t      nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "\t\t\t      nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = self.encoder(x)\n",
        "        return self.enc_out_1(h1), self.enc_out_2(h1)\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        if torch.cuda.is_available():\n",
        "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        else:\n",
        "            eps = torch.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "def loss_vae(recon_x, x, mu, logvar, criterion):\n",
        "    \"\"\"\n",
        "    recon_x: generating images\n",
        "    x: origin images\n",
        "    mu: latent mean\n",
        "    logvar: latent log variance\n",
        "    \"\"\"\n",
        "    mse = criterion(recon_x, x)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "    return mse + KLD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "class ResidualBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=(3, 3), stride=(1, 1)):\n",
        "\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.residual_block = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                            kernel_size=kernel_size, stride=stride, padding=1),\n",
        "            torch.nn.BatchNorm2d(in_channels),\n",
        "            torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
        "                            kernel_size=kernel_size, stride=stride, padding=1),\n",
        "            torch.nn.BatchNorm2d(out_channels),\n",
        "            torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.residual_block(x)\n",
        "\n",
        "\n",
        "class ResNetEncoder(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 n_ResidualBlock=8,\n",
        "                 n_levels=4,\n",
        "                 input_ch=3,\n",
        "                 z_dim=10,\n",
        "                 bUseMultiResSkips=True):\n",
        "\n",
        "        super(ResNetEncoder, self).__init__()\n",
        "\n",
        "        self.max_filters = 2 ** (n_levels+3)\n",
        "        self.n_levels = n_levels\n",
        "        self.bUseMultiResSkips = bUseMultiResSkips\n",
        "\n",
        "        self.conv_list = torch.nn.ModuleList()\n",
        "        self.res_blk_list = torch.nn.ModuleList()\n",
        "        self.multi_res_skip_list = torch.nn.ModuleList()\n",
        "\n",
        "        self.input_conv = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=input_ch, out_channels=8,\n",
        "                            kernel_size=(3, 3), stride=(1, 1), padding=1),\n",
        "            torch.nn.BatchNorm2d(8),\n",
        "            torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        for i in range(n_levels):\n",
        "            n_filters_1 = 2 ** (i + 3)\n",
        "            n_filters_2 = 2 ** (i + 4)\n",
        "            ks = 2 ** (n_levels - i)\n",
        "\n",
        "            self.res_blk_list.append(\n",
        "                torch.nn.Sequential(*[ResidualBlock(n_filters_1, n_filters_1)\n",
        "                                      for _ in range(n_ResidualBlock)])\n",
        "            )\n",
        "\n",
        "            self.conv_list.append(\n",
        "                torch.nn.Sequential(\n",
        "                    torch.nn.Conv2d(n_filters_1, n_filters_2,\n",
        "                                    kernel_size=(2, 2), stride=(2, 2), padding=0),\n",
        "                    torch.nn.BatchNorm2d(n_filters_2),\n",
        "                    torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if bUseMultiResSkips:\n",
        "                self.multi_res_skip_list.append(\n",
        "                    torch.nn.Sequential(\n",
        "                        torch.nn.Conv2d(in_channels=n_filters_1, out_channels=self.max_filters,\n",
        "                                        kernel_size=(ks, ks), stride=(ks, ks), padding=0),\n",
        "                        torch.nn.BatchNorm2d(self.max_filters),\n",
        "                        torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        self.output_conv = torch.nn.Conv2d(in_channels=self.max_filters, out_channels=z_dim,\n",
        "                                           kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.input_conv(x)\n",
        "\n",
        "        skips = []\n",
        "        for i in range(self.n_levels):\n",
        "            x = self.res_blk_list[i](x)\n",
        "            if self.bUseMultiResSkips:\n",
        "                skips.append(self.multi_res_skip_list[i](x))\n",
        "            x = self.conv_list[i](x)\n",
        "\n",
        "        if self.bUseMultiResSkips:\n",
        "            x = sum([x] + skips)\n",
        "\n",
        "        x = self.output_conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNetDecoder(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 n_ResidualBlock=8,\n",
        "                 n_levels=4,\n",
        "                 z_dim=10,\n",
        "                 output_channels=3,\n",
        "                 bUseMultiResSkips=True):\n",
        "\n",
        "        super(ResNetDecoder, self).__init__()\n",
        "\n",
        "        self.max_filters = 2 ** (n_levels+3)\n",
        "        self.n_levels = n_levels\n",
        "        self.bUseMultiResSkips = bUseMultiResSkips\n",
        "\n",
        "        self.conv_list = torch.nn.ModuleList()\n",
        "        self.res_blk_list = torch.nn.ModuleList()\n",
        "        self.multi_res_skip_list = torch.nn.ModuleList()\n",
        "\n",
        "        self.input_conv = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=z_dim, out_channels=self.max_filters,\n",
        "                            kernel_size=(3, 3), stride=(1, 1), padding=1),\n",
        "            torch.nn.BatchNorm2d(self.max_filters),\n",
        "            torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        for i in range(n_levels):\n",
        "            n_filters_0 = 2 ** (self.n_levels - i + 3)\n",
        "            n_filters_1 = 2 ** (self.n_levels - i + 2)\n",
        "            ks = 2 ** (i + 1)\n",
        "\n",
        "            self.res_blk_list.append(\n",
        "                torch.nn.Sequential(*[ResidualBlock(n_filters_1, n_filters_1)\n",
        "                                      for _ in range(n_ResidualBlock)])\n",
        "            )\n",
        "\n",
        "            self.conv_list.append(\n",
        "                torch.nn.Sequential(\n",
        "                    torch.nn.ConvTranspose2d(n_filters_0, n_filters_1,\n",
        "                                             kernel_size=(2, 2), stride=(2, 2), padding=0),\n",
        "                    torch.nn.BatchNorm2d(n_filters_1),\n",
        "                    torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if bUseMultiResSkips:\n",
        "                self.multi_res_skip_list.append(\n",
        "                    torch.nn.Sequential(\n",
        "                        torch.nn.ConvTranspose2d(in_channels=self.max_filters, out_channels=n_filters_1,\n",
        "                                                 kernel_size=(ks, ks), stride=(ks, ks), padding=0),\n",
        "                        torch.nn.BatchNorm2d(n_filters_1),\n",
        "                        torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        self.output_conv = torch.nn.Conv2d(in_channels=n_filters_1, out_channels=output_channels,\n",
        "                                           kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
        "\n",
        "    def forward(self, z):\n",
        "\n",
        "        z = z_top = self.input_conv(z)\n",
        "\n",
        "        for i in range(self.n_levels):\n",
        "            z = self.conv_list[i](z)\n",
        "            z = self.res_blk_list[i](z)\n",
        "            if self.bUseMultiResSkips:\n",
        "                z += self.multi_res_skip_list[i](z_top)\n",
        "\n",
        "        z = self.output_conv(z)\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "class ResNetAE(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_shape=(64, 64, 3),\n",
        "                 n_ResidualBlock=4,\n",
        "                 n_levels=2,\n",
        "                 z_dim=128,\n",
        "                 bottleneck_dim=128,\n",
        "                 bUseMultiResSkips=True):\n",
        "        super(ResNetAE, self).__init__()\n",
        "\n",
        "        assert input_shape[0] == input_shape[1]\n",
        "        image_channels = input_shape[2]\n",
        "        self.z_dim = z_dim\n",
        "        self.img_latent_dim = input_shape[0] // (2 ** n_levels)\n",
        "\n",
        "        self.encoder = ResNetEncoder(n_ResidualBlock=n_ResidualBlock, n_levels=n_levels,\n",
        "                                     input_ch=image_channels, z_dim=z_dim, bUseMultiResSkips=bUseMultiResSkips)\n",
        "        self.decoder = ResNetDecoder(n_ResidualBlock=n_ResidualBlock, n_levels=n_levels,\n",
        "                                     output_channels=image_channels, z_dim=z_dim, bUseMultiResSkips=bUseMultiResSkips)\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(self.z_dim * self.img_latent_dim * self.img_latent_dim, bottleneck_dim)\n",
        "        self.fc2 = torch.nn.Linear(bottleneck_dim, self.z_dim * self.img_latent_dim * self.img_latent_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        return self.fc1(h.view(-1, self.z_dim * self.img_latent_dim * self.img_latent_dim))\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = self.decoder(self.fc2(z).view(-1, self.z_dim, self.img_latent_dim, self.img_latent_dim))\n",
        "        return torch.sigmoid(h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decode(self.encode(x))\n",
        "\n",
        "\n",
        "class ResNetVAE(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_shape=(64, 64, 3),\n",
        "                 n_ResidualBlock=4,\n",
        "                 n_levels=2,\n",
        "                 z_dim=128,\n",
        "                 bottleneck_dim=128,\n",
        "                 bUseMultiResSkips=True):\n",
        "        super(ResNetVAE, self).__init__()\n",
        "\n",
        "        assert input_shape[0] == input_shape[1]\n",
        "        image_channels = input_shape[2]\n",
        "        self.z_dim = z_dim\n",
        "        self.img_latent_dim = input_shape[0] // (2 ** n_levels)\n",
        "\n",
        "        self.encoder = ResNetEncoder(n_ResidualBlock=n_ResidualBlock, n_levels=n_levels,\n",
        "                                     input_ch=image_channels, z_dim=z_dim, bUseMultiResSkips=bUseMultiResSkips)\n",
        "        self.decoder = ResNetDecoder(n_ResidualBlock=n_ResidualBlock, n_levels=n_levels,\n",
        "                                     output_channels=image_channels, z_dim=z_dim, bUseMultiResSkips=bUseMultiResSkips)\n",
        "\n",
        "        # Assumes the input to be of shape 256x256\n",
        "        self.fc21 = torch.nn.Linear(self.z_dim * self.img_latent_dim * self.img_latent_dim, bottleneck_dim)\n",
        "        self.fc22 = torch.nn.Linear(self.z_dim * self.img_latent_dim * self.img_latent_dim, bottleneck_dim)\n",
        "        self.fc3 = torch.nn.Linear(bottleneck_dim, self.z_dim * self.img_latent_dim * self.img_latent_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = self.encoder(x).view(-1, self.z_dim * self.img_latent_dim * self.img_latent_dim)\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = self.decoder(self.fc3(z).view(-1, self.z_dim, self.img_latent_dim, self.img_latent_dim))\n",
        "        return torch.sigmoid(h3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MvvQhk3dOpZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrJ9bScg9AgO"
      },
      "source": [
        "# Dataset module\n",
        "\n",
        "Module for obtaining and processing data. The transform function here normalizes image's pixels from [0, 255] to [-1.0, 1.0].\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33fWhE-h9LPq"
      },
      "source": [
        "class CustomTensorDataset(TensorDataset):\n",
        "    \"\"\"TensorDataset with support of transforms.\n",
        "    \"\"\"\n",
        "    def __init__(self, tensors):\n",
        "        self.tensors = tensors\n",
        "        if tensors.shape[-1] == 3:\n",
        "            self.tensors = tensors.permute(0, 3, 1, 2)\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "          transforms.Lambda(lambda x: x.to(torch.float32)),\n",
        "          transforms.Lambda(lambda x: 2. * x/255. - 1.),\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[index]\n",
        "\n",
        "        if self.transform:\n",
        "            # mapping images to [-1.0, 1.0]\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tensors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKNUImqUhIeq"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ebAJdjFmS08"
      },
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in7yLfmqtZTk"
      },
      "source": [
        "# Training hyperparameters\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Build training dataloader\n",
        "x = torch.from_numpy(train)\n",
        "train_dataset = CustomTensorDataset(x)\n",
        "\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Model\n",
        "model_type = 'ResNetAE'   # selecting a model type from {'cnn', 'fcn', 'vae', 'resnet'}\n",
        "# model_classes = {'fcn': fcn_autoencoder(), 'cnn': conv_autoencoder(), 'vae': VAE(), 'multi_encoder_autoencoder': multi_encoder_autoencoder(),'ResNetAE': ResNetAE(), 'ResNetVAE': ResNetVAE()}\n",
        "model = ResNetAE().cuda()\n",
        "\n",
        "# model = model_classes[model_type].cuda()\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyooN-JPm8sS"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoW1UrrxgI_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "934e3871-ce3a-4200-bdf0-9caeb9f7d787"
      },
      "source": [
        "\n",
        "best_loss = np.inf\n",
        "model.train()\n",
        "\n",
        "qqdm_train = qqdm(range(num_epochs), desc=format_str('bold', 'Description'))\n",
        "for epoch in qqdm_train:\n",
        "    tot_loss = list()\n",
        "    for data in train_dataloader:\n",
        "\n",
        "        # ===================loading=====================\n",
        "        img = data.float().cuda()\n",
        "        # print(img.shape)\n",
        "        # print(type(model))\n",
        "        # img = img.view(img.shape[0], -1)\n",
        "        # print(img.shape)\n",
        "        if model_type in ['fcn','multi_encoder_autoencoder']:\n",
        "            img = img.view(img.shape[0], -1)\n",
        "\n",
        "        # ===================forward=====================\n",
        "\n",
        "        output = model(img)\n",
        "        if model_type in ['vae']:\n",
        "            loss = loss_vae(output[0], img, output[1], output[2], criterion)\n",
        "        else:\n",
        "            loss = criterion(output, img)\n",
        "\n",
        "        tot_loss.append(loss.item())\n",
        "        # ===================backward====================\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # ===================save_best====================\n",
        "    mean_loss = np.mean(tot_loss)\n",
        "    if mean_loss < best_loss:\n",
        "        best_loss = mean_loss\n",
        "        # 保存模型的 state_dict\n",
        "        torch.save(model.state_dict(), 'best_model_{}.pt'.format(model_type))\n",
        "\n",
        "        # torch.save(model, 'best_model_{}.pt'.format(model_type))\n",
        "    # ===================log========================\n",
        "    qqdm_train.set_infos({\n",
        "        'epoch': f'{epoch + 1:.0f}/{num_epochs:.0f}',\n",
        "        'loss': f'{mean_loss:.4f}',\n",
        "    })\n",
        "    # ===================save_last========================\n",
        "    torch.save(model.state_dict(), 'last_model_{}.pt'.format(model_type))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m                                                                   \n",
            " \u001b[99m0/\u001b[93m100\u001b[0m\u001b[0m  \u001b[99m        -        \u001b[0m  \u001b[99m   -    \u001b[0m                                                                 \n",
            "\u001b[1mDescription\u001b[0m   0.0% |                                                                               |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                                                   \n",
            " \u001b[99m1/\u001b[93m100\u001b[0m\u001b[0m  \u001b[99m00:05:14<\u001b[93m08:39:25\u001b[0m\u001b[0m  \u001b[99m0.00it/s\u001b[0m  \u001b[99m1/100\u001b[0m  \u001b[99m0.2639\u001b[0m                                                  \n",
            "\u001b[1mDescription\u001b[0m   1.0% |                                                                               |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                                                   \n",
            " \u001b[99m2/\u001b[93m100\u001b[0m\u001b[0m  \u001b[99m00:10:30<\u001b[93m08:34:38\u001b[0m\u001b[0m  \u001b[99m0.00it/s\u001b[0m  \u001b[99m2/100\u001b[0m  \u001b[99m0.2474\u001b[0m                                                  \n",
            "\u001b[1mDescription\u001b[0m   2.0% |\u001b[97m█\u001b[0m                                                                              |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                                                   \n",
            " \u001b[99m2/\u001b[93m100\u001b[0m\u001b[0m  \u001b[99m00:10:30<\u001b[93m08:34:38\u001b[0m\u001b[0m  \u001b[99m0.00it/s\u001b[0m  \u001b[99m2/100\u001b[0m  \u001b[99m0.2474\u001b[0m                                                  \n",
            "\u001b[1mDescription\u001b[0m   2.0% |\u001b[97m█\u001b[0m                                                                              |"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-9b7a3b3a3d97>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# ===================backward====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# ===================save_best====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk0UxFuchLzR"
      },
      "source": [
        "# Inference\n",
        "Model is loaded and generates its anomaly score predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evgMW3OwoGqD"
      },
      "source": [
        "## Initialize\n",
        "- dataloader\n",
        "- model\n",
        "- prediction file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MBnXAswoKmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606501ba-8621-4bee-f373-9544ee4217fc"
      },
      "source": [
        "eval_batch_size = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# build testing dataloader\n",
        "data = torch.tensor(test, dtype=torch.float32)\n",
        "test_dataset = CustomTensorDataset(data)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=eval_batch_size, num_workers=1)\n",
        "eval_loss = nn.MSELoss(reduction='none')\n",
        "\n",
        "# load trained model\n",
        "checkpoint_path = f'best_model_ResNetAE.pt'\n",
        "state_dict = torch.load(checkpoint_path)\n",
        "\n",
        "# 重新实例化模型并加载权重\n",
        "model = ResNetAE()  # 替换为你的模型类\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# prediction file\n",
        "out_file = 'prediction.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-85-c80b3241ddf9>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(checkpoint_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anomality = list()\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(test_dataloader):\n",
        "    img = data.float().cuda()\n",
        "\n",
        "    if model_type in ['fcn','multi_encoder_autoencoder']:\n",
        "      img = img.view(img.shape[0], -1)\n",
        "\n",
        "    output = model.forward(img)\n",
        "    if model_type in ['vae']:\n",
        "      output = output[0]\n",
        "    if model_type in ['fcn','multi_encoder_autoencoder']:\n",
        "        loss = eval_loss(output, img).sum(-1)\n",
        "    else:\n",
        "        loss = eval_loss(output, img).sum([1, 2, 3])\n",
        "    anomality.append(loss)\n",
        "anomality = torch.cat(anomality, axis=0)\n",
        "anomality = torch.sqrt(anomality).reshape(len(test), 1).cpu().numpy()\n",
        "\n",
        "df = pd.DataFrame(anomality, columns=['score'])\n",
        "df.to_csv(out_file, index_label = 'ID')"
      ],
      "metadata": {
        "id": "_1IxCX2iCW6V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}